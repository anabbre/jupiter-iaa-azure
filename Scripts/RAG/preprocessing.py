import sys
from pypdf import PdfReader, PdfWriter
from typing import Dict, List, Any, Optional, Tuple
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../config')))
# from config.logger_config import logger, get_request_id, set_request_id
from logger_config import logger, get_request_id, set_request_id


import json
from pathlib import Path
import re
from collections import defaultdict
import shutil
import time


class PDFSectionExtractor:
    """
    Extrae secciones de PDFs con agrupaci√≥n inteligente por p√°ginas.

    Funcionalidad RAG optimizada:
    - Detecta autom√°ticamente chunks que comparten p√°ginas
    - Fusiona chunks redundantes en un solo fragmento por rango de p√°ginas
    - Preserva cohesi√≥n sem√°ntica y metadatos completos
    - Elimina duplicaci√≥n para mejorar eficiencia del sistema RAG
    """
    DATA_DIR = Path(__file__).parents[2] / "data"

    @staticmethod
    def extraer_secciones_por_niveles(
        nombre_pdf: str,
        niveles_filtro: Optional[List[int]] = None,
        output_dir: str = "optimized_chunks"
    ) -> List[str]:
        """
        Extrae y agrupa secciones del PDF eliminando redundancia.

        Args:
            nombre_pdf: Nombre del PDF
            niveles_filtro: Niveles jer√°rquicos a incluir
            output_dir: Directorio de salida (por defecto: optimized_chunks)

        Returns:
            Lista de archivos PDF generados (sin duplicaci√≥n)
        """
        try:
            request_id
        except NameError:
            request_id = get_request_id()
        start_time = time.time()
        logger.info("Iniciando extracci√≥n de secciones PDF",pdf=nombre_pdf,niveles_filtro=niveles_filtro,request_id=request_id,source="pdf_extractor")
        
        try:
            if not nombre_pdf.endswith('.pdf'):
                nombre_pdf += '.pdf'

            pdf_path = PDFSectionExtractor.DATA_DIR / nombre_pdf
            json_path = PDFSectionExtractor.DATA_DIR / f"{pdf_path.stem}_esquema.json"

            if not pdf_path.exists():
                logger.error("PDF no encontrado",pdf_path=str(pdf_path),request_id=request_id,source="pdf_extractor")
                raise FileNotFoundError(f"No se encontr√≥ el PDF: {pdf_path}")
            if not json_path.exists():
                logger.error("Esquema JSON no encontrado",json_path=str(json_path),request_id=request_id,source="pdf_extractor")
                raise FileNotFoundError(f"No se encontr√≥ el esquema: {json_path}")

            # Cargar PDF y esquema
            logger.info("Cargando PDF y esquema", request_id=request_id, source="pdf_extractor")
            reader = PdfReader(str(pdf_path))
            with open(json_path, 'r', encoding='utf-8') as f:
                esquema = json.load(f)

            logger.info("Archivos cargados",total_paginas=len(reader.pages),total_secciones_esquema=len(esquema),request_id=request_id,source="pdf_extractor")
            # Filtrar secciones por nivel
            logger.info("Filtrando secciones por nivel",niveles_solicitados=niveles_filtro, request_id=request_id,source="pdf_extractor")
            # Filtrar secciones por nivel
            secciones = PDFSectionExtractor._filtrar_secciones(esquema, niveles_filtro)

            if not secciones:
                logger.warning("No se encontraron secciones despu√©s del filtrado",niveles_filtro=niveles_filtro,request_id=request_id,source="pdf_extractor")
                print("‚ö† No se encontraron secciones con los filtros aplicados.")
                return []
            
            logger.info("Secciones filtradas exitosamente",secciones_filtradas=len(secciones),request_id=request_id,source="pdf_extractor")

            # Calcular rangos de p√°ginas para cada secci√≥n
            logger.debug("Calculando rangos de p√°ginas",request_id=request_id,source="pdf_extractor")
            secciones_con_rangos = PDFSectionExtractor._calcular_rangos_paginas(
                secciones, len(reader.pages)
            )

            # PASO CLAVE: Agrupar secciones por rango de p√°ginas √∫nico
            # Esto elimina la duplicaci√≥n de chunks que comparten p√°ginas
            logger.debug("Agrupando secciones por rango de p√°ginas",request_id=request_id,source="pdf_extractor")
            chunks_agrupados = PDFSectionExtractor._agrupar_por_rango_paginas(
                secciones_con_rangos
            )

            print(f"üìä An√°lisis de agrupaci√≥n:")
            print(f"   ‚Ä¢ Secciones originales: {len(secciones_con_rangos)}")
            print(f"   ‚Ä¢ Chunks √∫nicos (sin duplicaci√≥n): {len(chunks_agrupados)}")
            print(f"   ‚Ä¢ Reducci√≥n: {len(secciones_con_rangos) - len(chunks_agrupados)} chunks redundantes eliminados\n")

            # An√°lisis de agrupaci√≥n
            reduccion = len(secciones_con_rangos) - len(chunks_agrupados)
            logger.info("An√°lisis de agrupaci√≥n completado",secciones_originales=len(secciones_con_rangos),chunks_unicos=len(chunks_agrupados),chunks_redundantes_eliminados=reduccion,porcentaje_reduccion=f"{(reduccion/len(secciones_con_rangos)*100):.1f}%",request_id=request_id,source="pdf_extractor")
            
            # Crear directorio de salida (limpiar si ya existe)
            output_path = PDFSectionExtractor.DATA_DIR / output_dir / pdf_path.stem

            # Limpiar carpeta existente antes de generar nuevos chunks
            if output_path.exists():
                logger.info("Limpiando chunks anteriores",path=str(output_path),request_id=request_id,source="pdf_extractor")
                print(f"üóëÔ∏è  Limpiando chunks anteriores en {output_path.name}/")
                try:
                    shutil.rmtree(output_path)
                    logger.debug("Carpeta limpiada exitosamente",request_id=request_id,source="pdf_extractor")
                    print(f"‚úì Carpeta limpiada exitosamente\n")
                except Exception as e:
                    logger.warning("Error al limpiar carpeta",error=str(e),request_id=request_id,source="pdf_extractor")
                    print(f"‚ö† Advertencia al limpiar carpeta: {e}\n")

            output_path.mkdir(parents=True, exist_ok=True)

            # Generar PDFs optimizados (un PDF por rango √∫nico de p√°ginas)
            logger.info("Iniciando generaci√≥n de PDFs optimizados",chunks_a_generar=len(chunks_agrupados),request_id=request_id,source="pdf_extractor")
            archivos = PDFSectionExtractor._generar_pdfs_optimizados(
                reader, chunks_agrupados, output_path
            )
            duration = time.time() - start_time
            logger.info("Extracci√≥n completada exitosamente",archivos_generados=len(archivos),duration=f"{duration:.3f}s",output_path=str(output_path),request_id=request_id,source="pdf_extractor",process_time=f"{duration:.3f}s")
            return archivos
        except Exception as e:
            duration = time.time() - start_time
            logger.error("Error en extracci√≥n de secciones",error=str(e),tipo_error=type(e).__name__,pdf=nombre_pdf,duration=f"{duration:.3f}s",request_id=request_id,source="pdf_extractor",process_time=f"{duration:.3f}s")
            raise

    @staticmethod
    def _filtrar_secciones(
        esquema: List[Dict[str, Any]],
        niveles_filtro: Optional[List[int]]
    ) -> List[Dict[str, Any]]:
        """Filtra secciones por nivel jer√°rquico"""
        try:
            request_id
        except NameError:
            request_id = get_request_id()
            
        logger.debug("Agrupando por rango de paginas",secciones=len(secciones),request_id=request_id,source="pdf_extractor")
        
        secciones = []
        for seccion in esquema:
            if niveles_filtro and seccion['nivel'] not in niveles_filtro:
                continue
            if seccion['pagina'] is None:
                continue
            secciones.append({
                'titulo': seccion['titulo'],
                'pagina': seccion['pagina'],
                'nivel': seccion['nivel']
            })
        return secciones

    @staticmethod
    def _calcular_rangos_paginas(
        secciones: List[Dict[str, Any]],
        total_paginas: int
    ) -> List[Dict[str, Any]]:
        """
        Calcula el rango de p√°ginas [inicio, fin) para cada secci√≥n.

        L√≥gica:
        - Una secci√≥n va desde su p√°gina inicial hasta donde comienza la siguiente
        - La √∫ltima secci√≥n llega hasta el final del documento
        - Si dos secciones est√°n en la misma p√°gina, ambas tendr√°n el mismo rango
        """
        try:
            request_id
        except NameError:
            request_id = get_request_id()
            
        logger.debug("Calculando rangos de p√°ginas",secciones=len(secciones),total_paginas=total_paginas,request_id=request_id,source="pdf_extractor") 
        for i, seccion in enumerate(secciones):
            if i < len(secciones) - 1:
                # La secci√≥n termina donde comienza la siguiente
                seccion['pagina_fin'] = secciones[i + 1]['pagina']
            else:
                # √öltima secci√≥n: hasta el final del documento
                seccion['pagina_fin'] = total_paginas

            # Asegurar que siempre incluya al menos la p√°gina de inicio
            if seccion['pagina_fin'] == seccion['pagina']:
                seccion['pagina_fin'] = seccion['pagina'] + 1

        return secciones

    @staticmethod
    def _agrupar_por_rango_paginas(
        secciones: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        FUNCIONALIDAD CLAVE PARA RAG:
        Agrupa todas las secciones que comparten el mismo rango de p√°ginas.

        Esto elimina la duplicaci√≥n de chunks para la misma p√°gina,
        mejorando la precisi√≥n y eficiencia del sistema RAG.

        Args:
            secciones: Lista de secciones con rangos de p√°ginas calculados

        Returns:
            Lista de chunks √∫nicos, cada uno representando un rango √∫nico de p√°ginas
            con metadatos de todas las secciones incluidas
        """
        try:
            request_id
        except NameError:
            request_id = get_request_id()
            
        logger.debug("Inicio agrupaci√≥n por rango de p√°ginas",secciones=len(secciones),request_id=request_id,source="pdf_extractor")
        
        # Diccionario para agrupar por rango de p√°ginas (clave: tupla (inicio, fin))
        grupos: Dict[Tuple[int, int], List[Dict[str, Any]]] = defaultdict(list)

        for seccion in secciones:
            rango = (seccion['pagina'], seccion['pagina_fin'])
            grupos[rango].append(seccion)

        # Crear chunks √∫nicos fusionando secciones del mismo rango
        chunks_unicos = []
        for (pagina_inicio, pagina_fin), secciones_grupo in grupos.items():
            # Fusionar t√≠tulos de todas las secciones en este rango
            titulos = [s['titulo'] for s in secciones_grupo]
            niveles = [s['nivel'] for s in secciones_grupo]

            # Crear t√≠tulo compuesto (usa el primero como principal)
            titulo_principal = titulos[0]

            # Construir metadatos completos
            chunk_unico = {
                'pagina_inicio': pagina_inicio,
                'pagina_fin': pagina_fin,
                'titulo_principal': titulo_principal,
                'titulos_incluidos': titulos,  # Todas las secciones en este chunk
                'niveles': niveles,
                'num_secciones': len(secciones_grupo),
                'secciones_fusionadas': len(secciones_grupo) > 1  # Flag de fusi√≥n
            }

            chunks_unicos.append(chunk_unico)

        # Ordenar por p√°gina de inicio
        chunks_unicos.sort(key=lambda x: x['pagina_inicio'])

        return chunks_unicos

    @staticmethod
    def _generar_pdfs_optimizados(
        reader: PdfReader,
        chunks: List[Dict[str, Any]],
        output_path: Path
    ) -> List[str]:
        """
        Genera un PDF por cada chunk √∫nico (rango de p√°ginas sin duplicaci√≥n).

        Cada PDF incluye:
        - Las p√°ginas originales del PDF con formato preservado
        - Metadatos con todas las secciones incluidas en ese chunk
        - Nombre descriptivo indicando el contenido
        """
        try:
            request_id
        except NameError:
            request_id = get_request_id()
                
            
        logger.info("Iniciando generaci√≥n de PDFs",chunks_totales=len(chunks),output_path=str(output_path),request_id=request_id,source="pdf_extractor")
        archivos = []
        errores = 0 # Errores por chunk

        for idx, chunk in enumerate(chunks):
            pagina_inicio = chunk['pagina_inicio']
            pagina_fin = chunk['pagina_fin']
            titulo_principal = chunk['titulo_principal']
            num_secciones = chunk['num_secciones']

            # Crear nombre descriptivo del archivo
            nombre_limpio = PDFSectionExtractor._limpiar_nombre_archivo(titulo_principal)

            # A√±adir sufijo si contiene m√∫ltiples secciones fusionadas
            if num_secciones > 1:
                sufijo = f"_y_{num_secciones-1}_mas"
            else:
                sufijo = ""

            pdf_file = output_path / f"{idx + 1:03d}_{nombre_limpio}{sufijo}.pdf"

            try:
                logger.debug("Generando PDF del chunk",chunk_numero=idx,paginas=f"{pagina_inicio+1}-{pagina_fin}",num_paginas=num_paginas,num_secciones=num_secciones,titulo=titulo_principal,request_id=request_id,source="pdf_extractor")
                # Crear writer y agregar p√°ginas del chunk
                writer = PdfWriter()

                for page_num in range(pagina_inicio, pagina_fin):
                    if page_num < len(reader.pages):
                        writer.add_page(reader.pages[page_num])

                # A√±adir metadatos al PDF
                metadata = {
                    '/Title': titulo_principal,
                    '/Subject': f"P√°ginas {pagina_inicio+1}-{pagina_fin}",
                    '/Keywords': ', '.join(chunk['titulos_incluidos'][:5]),  # Max 5 t√≠tulos
                }
                writer.add_metadata(metadata)

                # Guardar PDF optimizado
                with open(pdf_file, 'wb') as output_file:
                    writer.write(output_file)

                num_paginas = pagina_fin - pagina_inicio
                archivos.append(str(pdf_file))

                # Log detallado
                if num_secciones > 1:
                    print(f"‚úì Chunk fusionado: {pdf_file.name}")
                    print(f"  ‚îî‚îÄ {num_paginas} p√°gina(s) | {num_secciones} secciones combinadas")
                    print(f"  ‚îî‚îÄ Secciones: {', '.join(chunk['titulos_incluidos'][:3])}{'...' if num_secciones > 3 else ''}")  
                    logger.info("Chunk fusionado generado",archivo=pdf_file.name,num_paginas=num_paginas,num_secciones=num_secciones,secciones=chunk['titulos_incluidos'][:3],request_id=request_id,source="pdf_extractor")
                else:
                    print(f"‚úì Chunk √∫nico: {pdf_file.name} ({num_paginas} p√°gina(s))")
                    logger.info("Chunk √∫nico generado",archivo=pdf_file.name,num_paginas=num_paginas,request_id=request_id,source="pdf_extractor")

            except Exception as e:
                errores += 1
                print(f"‚úó Error al generar {pdf_file.name}: {e}")
                logger.error(f"‚úó Error al generar {pdf_file.name}: {e}")

        print(f"\n‚úÖ Total chunks optimizados generados: {len(archivos)}")
        print(f"üìà Mejora para RAG: Sin duplicaci√≥n de p√°ginas, chunks sem√°nticamente coherentes")  
        logger.info("Generaci√≥n de PDFs completada",archivos_generados=len(archivos),errores=errores,request_id=request_id,source="pdf_extractor")
        
        return archivos

    @staticmethod
    def _limpiar_nombre_archivo(nombre: str) -> str:
        """Limpia y normaliza nombres para usar como archivos"""
        # Eliminar caracteres no v√°lidos
        nombre_limpio = re.sub(r'[<>:"/\\|?*\[\]]', '', nombre)
        # Reemplazar espacios y puntos m√∫ltiples
        nombre_limpio = re.sub(r'\s+', '_', nombre_limpio)
        nombre_limpio = re.sub(r'\.+', '.', nombre_limpio)
        # Limitar longitud
        return nombre_limpio[:80].strip('._')


def extraer_secciones_por_niveles(
    nombre_pdf: str,
    niveles: List[int]
) -> List[str]:
    """
    Funci√≥n de conveniencia para extraer secciones con agrupaci√≥n optimizada.

    Args:
        nombre_pdf: Nombre del archivo PDF
        niveles: Niveles jer√°rquicos a incluir (ej: [1, 2] para cap√≠tulos y art√≠culos)

    Returns:
        Lista de archivos PDF generados (sin duplicaci√≥n)
    """
    return PDFSectionExtractor.extraer_secciones_por_niveles(
        nombre_pdf=nombre_pdf,
        niveles_filtro=niveles
    )


if __name__ == "__main__":
    from logger_config import set_session_id
    
    # Crear sesi√≥n para este proceso
    session_id = f"pdf_extract_{int(time.time())}"
    set_session_id(session_id)
    
    print("=" * 70)
    print("EXTRACTOR DE CHUNKS OPTIMIZADO PARA RAG")
    print("Agrupaci√≥n autom√°tica | Sin duplicaci√≥n | Metadatos completos")
    print("=" * 70)
    print()
    
    logger.info("Iniciando PDF extractor - Proceso principal",session_id=session_id,source="pdf_extractor")


    try:
        archivos = extraer_secciones_por_niveles(
            nombre_pdf="Libro-TF.pdf",
            niveles=[0, 1, 2, 3, 4]  # Cap√≠tulos (nivel 1) y Art√≠culos (nivel 2)
        )

        print(f"\n{'='*70}")
        print(f"‚úÖ Proceso completado exitosamente")
        print(f"üìÅ Chunks generados: {len(archivos)}")
        print(f"üìÇ Ubicaci√≥n: data/optimized_chunks/Libro-TF/")
        print(f"üí° Beneficios RAG:")
        print(f"   ‚Ä¢ Sin p√°ginas duplicadas en m√∫ltiples chunks")
        print(f"   ‚Ä¢ Fusi√≥n autom√°tica de secciones en la misma p√°gina")
        print(f"   ‚Ä¢ Metadatos completos para cada chunk")
        print(f"   ‚Ä¢ Mayor precisi√≥n en recuperaci√≥n de informaci√≥n")
        print(f"{'='*70}")
        logger.info("Proceso de PDF extractor completado exitosamente",archivos_generados=len(archivos),session_id=session_id,source="pdf_extractor")

    except Exception as e:
        print(f"‚ùå Error: {e}")
        logger.error("Error en PDF extractor",error=str(e),tipo_error=type(e).__name__,session_id=session_id,source="pdf_extractor")